---
title: "finalProject"
author: "Eric Appelbaum & Varvara Valischenko"
date: "May 22, 2019"
output: html_document
---

# Cell Phone Data

## Intro

Online reviews of products can give a buyer a good idea on which item they should choose. It is also common knowledge that online reviews are subjective, can be very arbitrary and are biased in ways unrelated to the product itself. There are a lot of patterns to analyse in these subjective reviews, and we are particularly interested in looking at reviews of cellphones - something that people heavily rely on in their daily life.

## Libraries

```{r}
library(plyr)
library(stringr)
library(tidyverse)
library(lubridate)
library(broom)
```

## Data

### Raw Data

We are using the dataset [1.4 Million Phone Reviews](https://www.kaggle.com/masaladata/14-million-cell-phone-reviews) from Kaggle. This dataset encompasses over 1.4 million reviews across various brands, models, countries, languages, and websites. The reviews include a block of text, as well as a rating on a scale of 1 to 10. It appears that most of these ratings were not originally given on this scale, but the people who collected this data had already done the work of adjusting the rating to be out of 10.

```{r}
review1 <- read.csv("data/phone_user_review_file_1.csv")
review2 <- read.csv("data/phone_user_review_file_2.csv")
review3 <- read.csv("data/phone_user_review_file_3.csv")
review4 <- read.csv("data/phone_user_review_file_4.csv")
review5 <- read.csv("data/phone_user_review_file_5.csv")
review6 <- read.csv("data/phone_user_review_file_6.csv")
```

```{r}
reviews <- rbind.fill(review1, review2, review3, review4, review5, review6)
```

The data is contained within six different CSVs which we can read in with read.csv. They all have the same format, so they can easily be stitched together into one large data frame with [rbind](http://www.endmemo.com/program/R/rbind.php) from the dplyr package in tidyverse.

### Data Cleaning

```{r}
reviews$phone_url = substring(reviews$phone_url, 13, str_length(reviews$phone_url)-1)
reviews$date = as.Date(reviews$date, "%m/%d/%Y")

reviews <- reviews %>%
  na.omit()

reviews
```

In order to clean up the data, there are some changes we want to make. First, the phone_url serves as an identifier for the make and model of a phone; however, all phone-url entries start with /cellphone/ and end with /. We remove these to get a cleaned version of phone_url that we will use in the next data wrangling process. We chose to use phone_url instead of product as the phone identifier, since the values are more consistent in this attribute.

We also need to type convert the date from M/D/Y format into a digital date value to allow us to analyse the date numerically and not as a string. This can be done with the conversion function [as.Date](https://www.statmethods.net/input/dates.html).

Lastly, we decide to omit any data that contains NA values. This is done by feeding the dataframe through the function na.omit. Making any calculations with attributes that are NA would mess with the calculations. Because we have over 1.4 million reviews that we pull from, we have the luxury of being able to omit all NA entries without hurting the magnitide of our sample size. (The dataset went from 1.4 million values to 1.3 million.)

```{r}
reviews_bm <- reviews %>%
  separate(phone_url, c("brand", "model"), sep = "-", extra = "merge")

reviews_bm
```

The most common way people refer to a phone is by it's brand and model name: E.g. Samsung Galaxy S8. These only exist together as part of the phone_url, but in order to do analysis on only a specific brand of phone or a specific model we need to separate them. Fortunately, the phone_url uses a standardized layout: [brand]-[model]. All we have to do is separate phone_url on the first - character. This is done with the tidyr function [separate](https://www.rdocumentation.org/packages/tidyr/versions/0.8.3/topics/separate), with the extra flag set to "merge" so that the phone_url only gets split on the first "-".

## EDA

Now that our data is clean and usable, we can think about what interesting patterns we can find in the data. One interesting piece of information we are given is country of the person writing the review, so there is a chance that we can observe a correlation in average scores given and country. Do people from different countries tend to be more positive or negative with their reviews?

### Country Optimism
```{r}
country_reviews = reviews_bm %>%
  group_by(country) %>%
  summarize(mean_score = mean(score))

country_reviews

country_reviews %>%
  ggplot() +
  geom_bar(aes(reorder(country, -mean_score),mean_score), stat = "identity") + coord_cartesian(ylim=c(6.0,10.0)) +
  geom_bar(data=subset(country_reviews, mean_score==min(mean_score)), aes(country, mean_score), fill="red", stat="identity") +
  geom_bar(data=subset(country_reviews, mean_score==max(mean_score)), aes(country, mean_score), fill="cyan", stat="identity")

```
We were interested in seeing the average score by country of the user. This was achieved by grouping the data by country using the function [group_by](https://dplyr.tidyverse.org/reference/group_by.html) and summarizing the grouped data by the mean score using [summarize](https://dplyr.tidyverse.org/reference/summarise.html). This was then plotted with a bar graph using [ggplot](https://www.statmethods.net/advgraphs/ggplot2.html) and [geom_bar](https://ggplot2.tidyverse.org/reference/geom_bar.html), and the minimum and maximum values were highlighted with a subset of the bars. From this, we can see that the most optimistic reviewers are from Switzerland (country code ch) and the most pessimistic are from India (country code in).

We also deciding looking at the way in which reviews change over time.

### Brand Ratings
```{r}

brand_reviews = reviews_bm %>%
  filter(!is.na(score)) %>%
  group_by(brand) %>%
  summarize(mean_score = mean(score), count=n())

top_10_brands <- brand_reviews[order(brand_reviews$count, decreasing=T),] %>% head(10)

top_10_brands %>%
  ggplot() +
  geom_bar(aes(reorder(brand, -mean_score),mean_score), stat = "identity") + coord_cartesian(ylim=c(6.0,10.0)) + labs(x="brand")

```
In order to see how people are rating the world's most popular phone brands, we decided to filter out the top 10 brands based on the number of reviews. We do this by first grouping the dataframe by brand, then summarizing by the mean score as well as the count of entities. We then order this dataframe by the count in decreasing order and take the first 10 entities using the function head. We then plot this once again using ggplot and geom_bar.

Next we look at a specific example that we suspected to have a change in rating.

### Galaxy Note 7
```{r}

note_reviews = reviews %>%
  filter(phone_url=="samsung-galaxy-note-7") %>%
  group_by(date) %>%
  summarize(mean_score=mean(score))
note_reviews

note_reviews %>%
  ggplot(aes(date,mean_score)) +
  geom_point() + geom_smooth(method=lm) + geom_vline(xintercept = as.numeric(as.Date("2016-09-02")), color="red")

```
Knowing about the [unfortunate events](https://www.theverge.com/2016/9/2/12767670/samsung-galaxy-note-7-recall-fire-risk) following the release of the Note 7, we were interested to see what the effect was on the online rating. We mapped the mean score for the phone over time, and plotted the date when the phone was recalled (September 2nd, 2016). To do this, we filtered the dataframe by phone name to only display data about the Note 7, then grouped by date and summarized by the mean score to get the mean score for each day. Then, we chose to display the results with a smoothed line graph using [geom_smooth](https://ggplot2.tidyverse.org/reference/geom_smooth.html) to illustrate how the scores trended over time. We prefer to use geom_smooth in this case to see a general trend over time instead of simply connecting the points like a regular line graph. We then added a vertical line indicating the day phones started to malfunction and were recalled, the date of which was put manually as 2016-09-02. It can be seen that the scores started to drop a little before the phone was recalled.

## Hypothesis Testing and Linear Regression

Now we will be taking those top 10 most reviewed brands and comparing how their review performance over the years compares to the review performance of the cellphone industry overall as well as how they compare to each other. The first thing to do is to figure out the status of the industry overall.

```{r}
reviews_bm %>%
  filter(date > 1999-01-01) %>%
  mutate(year = format(date, "%Y")) %>%
  ggplot() +
  geom_boxplot(aes(factor(year), score))
```

We took all of the reviews since 1999 and gathered them together by year. We then took each year and visualized the disribution via a boxplot. From just this visualization we can tell a few things: the median of each yearly distribution has increased recently and the [interquartile range](https://stattrek.com/statistics/dictionary.aspx?definition=interquartile%20range) has gotten smaller. We cannot, however, tell how the general trend of the data. In order to do this, we will use [linear regression](https://medium.com/data-science-group-iitr/linear-regression-back-to-basics-e4819829d78b).

```{r}
reviews_y <- reviews_bm %>%
  filter(date > 1999-01-01) %>%
  mutate(year = as.numeric(format(date, "%Y")))

fit <- lm(score~year, data = reviews_y)
tidy(fit)
```

We take the data we had before, and utilize the [lm function](https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/lm) to create the linear regression. We use the formula "score~year" because we want to see how score changes as a result of the increase in year. This regression estimates that every year, scores generally increase by .03 points. While this may be small, the [p-value](https://blog.minitab.com/blog/adventures-in-statistics-2/how-to-interpret-regression-analysis-results-p-values-and-coefficients) indicates that this is statistically significant value that closely adheres to the genreal trend of the data.

```{r}
brand_reviews <- reviews_y %>%
  group_by(brand) %>%
  summarize(mean_score = mean(score), count = n()) %>%
  filter(count >= 1000)

top_10_brands <- brand_reviews[order(brand_reviews$count, decreasing=T),] %>%
  head(10)

reviews_top_10 <- top_10_brands %>%
  join(reviews_y) %>%
  na.omit()
```

```{r}
reviews_top_10 %>%
  filter(brand == "huawei") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="huawei")

reviews_top_10 %>%
  filter(brand == "samsung") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="samsung")

reviews_top_10 %>%
  filter(brand == "apple") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="apple")

reviews_top_10 %>%
  filter(brand == "nokia") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="nokia")

reviews_top_10 %>%
  filter(brand == "sony") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="sony")

reviews_top_10 %>%
  filter(brand == "lg") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="lg")

reviews_top_10 %>%
  filter(brand == "motorola") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="motorola")

reviews_top_10 %>%
  filter(brand == "blackberry") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="blackberry")

reviews_top_10 %>%
  filter(brand == "htc") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="htc")

reviews_top_10 %>%
  filter(brand == "lenovo") %>%
  ggplot(aes(factor(year), score)) +
  geom_boxplot() + labs(title="lenovo")
```

Here we get the distributions over the years for the top 10 most reviewed brands. These boxplots are fairly overwhelming, with only a few yielding information very clearly: such as, lenovo is clearly on a downward trend. When comparing so many variables, a linear regression is the best way.

```{r}
brand_fit <- lm(score~year*brand, data = reviews_top_10)
tidy(brand_fit)
```

In this linear regression, we want to see how the combination of year and brand affect score. For this reason we use "*" in the formula. Now, this table takes some unpacking, but it can tell us some very interesting things. First, I want to mention that all p-values are very low, indicating that all of these results are statistically significant. What we will be focusing on are the year and year:[brand] rows. In multivariate linear regression, the lm function chooses the first category alphabetically as the benchmark - in the case it is Apple. 

With this knowlege, we see that over the years, Apple sees an increase in review scores of .15 points/year, far higher than the average we saw before. From the year:[brand] rows, we actually see that every brand's change in score per year is less than Apple's (i.e. Blackblerry changes .059 less per year than Apple, putting it at ~.097/year). All brands that are less than -.15 on this chart are experiencing a negative score change per year (e.g. HTC, Lenovo, Nokia, Sony).

We can assume that, due to the vast difference between top performing brands and the industry average, the majority of the increase that is observed is coming from the top few.